## TIL 2025-08-28

### 오늘 배운 것

# 데이터모양 확인
print(x_train.shape, y_train.shape)
print(x_test.shape, y_test.shape)

# 신경마 설계하기
my_mnist_model = Sequential()#뼈대 생성

#입력층
my_mnist_model.add(InputLayer(shape=(28,28)))
my_mnist_model.add(Flatten()) #평탄화 작업실시-> 784개의 특성으로 구성된 1차원데이터

# 중간층
my_mnist_model.add(Dense(units=128, activation="sigmoid")) # step func와 유사한 대체활성화 함수
my_mnist_model.add(Dense(units=256, activation="sigmoid"))
my_mnist_model.add(Dense(units=512, activation="sigmoid"))
my_mnist_model.add(Dense(units=256, activation="sigmoid"))
my_mnist_model.add(Dense(units=128, activation="sigmoid"))
# 출력층
my_mnist_model.add(Dense(units=10, activation="sigmoid")) # 다중분류용 활성화함수 적용

# 학습방법 설정
my_mnist_model.compile(loss="sparse_categorical_crossentropy", # 정답데이터가 확률 형태로 로딩 상태이면 sparse 안써도 됨
                       optimizer="Adam",
                       metrics=['accuracy'])

# 학습
h = my_mnist_model.fit(x_train, y_train,
                   validation_split=0.2, # 검증데이터 분할
                   epochs = 20)