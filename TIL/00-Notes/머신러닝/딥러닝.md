## 딥러닝
- 인간의 신경망을 모방하여 학습 및 예측
- 생성형 AI
  - 피지컬 ai
  - 에이전트 ai

</br>


- Loss funtion(손실 함수)
  - 현재 모델의 오차를 계산해주는 함수
    선형회귀 : mse
    선형분류 :  crossEntropy

- optimizer
  - 어느 방향으로 수정해야 할지 알려준다


</br>

분류 정답 데이터가 정해진 선택지 범주형 카테고리
  - 이진분류: class가 2개일때 -> 예, 아니요
  - 다중분류: class가 3개 이상일때 

</br>

회귀 정답데이터가 연속적인 사이값을 만드는 연속형 수치형 

Loss 오차를 계산함
optimizer 방향성을 알려준다
선형기반 모델 학습가능

metrics 모델 평가

- 예측 평가
  - 분류 : Acc 
  - 회귀 : 오차로 계산


- 전체 데이터 특성 : 전역성
- 부분 데이터 특성 : 지역성 -> 특성을 뽑는다  특성을 뽑기 위해 필터를 사용
  - feature map 지역 특성
- 필터링
- CNN (Convolution Neural Network) 과정
  1. 같은 픽셀의 위치는 곱한다
  2. 각 패치(지역 그룹)끼리 곱을 더한다
  3. 새로운 픽셀로 사용한다
  
- 오차 역전파
  1. w,b 초기화 (랜덤)
  2.  y' 계산
  3.  오차를 구함 e = y - y'
  4.  e/w + w -> w' e/b + b -> b' 1epoch
  5.  학습률을 곱한다? 



## 과대적합 피하는 방법- 데이터 증강 (이미지 증식)
- 과대적합이 일어나는 이유 중 하나는 훈련데이터가 부족하기 떄문
- 훈련 데이터가 충분히 많다면 과대적합을 줄일 수 있음
- 데이터 증강이란 훈련 데이터를 유사하고 다양하게 변형하여 새로운 훈련 데이터처럼 추가적으로 사용함으로써 마치 훈련 데이터 수가 많아진 것처럼 하는것

