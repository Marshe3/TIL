## 머신 러닝

## AI vs ML vs DL

- 인공지능(Artificial Intelligence)

사고나 학습등 인간이 가진 지적 능력을 컴퓨터를 통해 구현하는 기술

- 머신러닝

컴퓨터가 스스로 학습하여 인공지능의 성능을 향상 시키는 기술 방법

- 딥러닝

인간의 뉴런과 비슷한 인공신경망 방식으로 정보를 처리

### 머신 러닝

- 데이터를 기반으로 학습을 시켜서 예측하게 만드는 기법
- 인공지능의 한 분야로 컴퓨터가 학습할 수 있도록 하는 **알고리즘기술**을 개발하는 분야
- 통계학, 데이터 마이닝, 컴퓨터과학이 어우러진 분야

### 인공지능 단계

- 약한인공지능
    - 특정분양를 위해 제작된 인공지능
    - 체스, 퀴즈, 자율주행, 상품 추천, 번역시스템, 알파고(특정임무수행)등

- 강한인공지능
    - 모든 방면에서 인간급의 인공지능
    - 사고, 계획, 문제해결, 추상화, 복잡한개념학습

- 초인공지능
    - 과학기술, 사회적 능력 등 모든 영역에서 인간보다 뛰어남

### 머신러닝 종류

- 지도학습(SUpervised Learning)
    - 데이터에 대한 Label(명시적인 답)이 주어진 상태에서 컴퓨터를 학습시키는 방법
    - 분류(Classification)와 회귀(Regression)
    
- 비지도학습(Unsupervised Learning)
    - 데이터에 대한 Label(명시적인 답)이 없는 상태에서 컴퓨터를 학습시키는 방법
    - 데이터의 숨겨진 특징, 구조, 패턴을 파악하는데 사용
    - 클러스터링(CLustering), 차원축소(Dimensionality Reduction)등

- 강화학습(Reinforcement Learning)
    - 지도학습과 비슷하지만 완전한 답(Label)을 제공하지 않음
    - 기계는 더 많은 보상을 얻을 수 있는 방향으로 행동을 학습
    - 주로 게임이나 로봇을 학습시키는데 많이 사용

### 머신러닝 과정

1. Problem Identification(문제정의)
2. Data Collect(데이터 수집)
    - File(CSV, XML, JSON)
    - Database
    - Web Crawler (뉴스, SNS, 블로그)
    - IoT 센서를 통한 수집
    - Survey
3. **Data Preprocessing(데이터 전처리)**
    - 결측치, 이상치 처리
    - Feature Engineering(특성공학): Scaling(단위 변환), Encoding(범주형 → 수치형), Minning (수치형→범주형), Transform(새로운 속성 추출)
4. EDA(Exploratory Data Analysis)(탐색적 데이터분석)
    - 기술통계, 변수간 상관관계
    - 시각화: pandas, matplotlib, seaborn
    - Feature Selection (사용할 특성 선택)
5. Model 선택, **Hyper Parameter 조정**
    - 목적에 맞는 적절한 모델 선택
    - KNN, SVm, Linear Regression, Ridge, Lasso, Decision Tree, Random forest, CNN, RNN …
    - Hyper Parameter
        
        model의 성능을 개선하기 위해 사람이 직접 넣는 parameter
        
6. Training(학습)
    - **model.fit(X_train,y_train)**
        - train 데이터와 test 데이터를 7:3 정도로 나눔
        - train 데이터의 문제와 정답으로 모델 학습
    - **model.predict(X_test)**
        - test 데이터의 문제를 넣고 정답을 예측
7. Evaluation(평가)

| 분류 | 회귀 |
| --- | --- |
| accuracy(정확도) 단순 정답 | **MSE**(Mean Squared Error |
| recall(재현율) 데이터 기준  | RMSE(Root Mean Squared Error |
| precision(정밀도) | R**2(R square) |
| f1 score |  |
| roc곡선의 auc |  |
- TP(True Positive): 진짜를 진짜라고 맞춤
- FP(False Positive): 가짜를 진짜라고 착각함 (ex 무죄인데 유죄라고)
- FN(False Negative): 진짜를 가짜라고 놓침 (ex 암인데 암아니라고)
- 재현율(Recall): 실제 진짜 중 모델이 진짜라고 잘 찾아낸 비율
    - TP / (TP + FN)
- 정밀도(Precision): 진짜라고 판별한 것 중 실제로 진짜인 비율
    - TP / (TP + FP)

### 트레인, 테스트 데이터




knn_model=KNeighborsClassifier(n_neighbors=1)
knn_model.fit(문제 , 답)
knn_model.predict(예측값을 얻고 싶은 데이터)
score=metrics.accuracy_score(실제답, 예측결과 )




- 과대적합
    - train(학습) 데이터에 너무 과도하게 학습되어 train 데이터에만 잘 동작하고 test)평가)에서는 예측 성능이 저하되는 현상
- 과소적합
    - -Train 데이터를 충분히 반영하지 못해 train, test 데이터 모두에서 예축성능이 저하되는 현상(학습을 제대로 하지 못한것)
- 일반화
    - Train 데이터로 학습한 모델이 test 데이터에 대해서도 정확히 예측하는 현상

### 모델의 복잡도 해결

- 일반적으로 데이터 양이 많으면 일반화에 도움이 됨
- 주어진 훈련데이터의 다양성 보장되어야 함
- 편중된 데이터를 모으는 것 지양
- 규제를 통해 모델의 복잡도를 적정선으로 설정

## knn

- 유유상종의 개념과 유사
- 새로운 데이터 포인트와 가장 가까운 훈련 데이터셋의 데이터 포인트를 찾아 예측
- k값/에 따라 가까운 이웃의  수가 결정
- 분류와 회귀에 모두 사용 가능

### 장단점 및 키워드

- n-neighbors : 이웃의수
- 이해하기 매우 쉬운 모델, 큰 조정 없이도 나쁘지 않은 성능을 발휘하는 기초모델
- 새로운 테스트 데이터 세트가 들어오면 훈련데이터 세트와의 거리를 계산 해서 훈련데이터 세트가 크면(특성,샘플의 수) 예측이 느려짐

거리를 측정하기 때문에 데이터의 스케일(scale) 조정이 필요할 수 있음

직접적인 예측에 사용되기보다는 주로 데이터를 파악하기 위한 용도로 가볍게 사용

### Decision Tree

- 스무고개 하듯이 질문을 하고, 예/아니오 답변을 반복하며 학습
- 특정 기준(질문)에 따라 데이터를 구분하는 모델
- 분류와 회귀에 모두 사용 가능

### 지니 불순도(Gini Impurity)

- 해당 범주 안에 서로 다른 데이터가 얼마나 섞여 있는지를 뜻함
- 결정 트리 모델의 노드 분할 기준
- 각 질문들이 얼마나 좋은 질문인지 수치로 파악 할 수 있음
- 0~0.5 사이 값을 범위로 가짐
- 불순도가 0에 가까울수록 잘 분류된 것 (좋은 질문)
- 불순도가 0.5라면 데이터가 5:5 비율로 섞여서 분류된 것 (좋지 않은 질문)